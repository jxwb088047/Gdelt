2015-10~12
http://eng.the-liberty.com/2015/6066/

Will the 2045 Problem Be Solved? : Establishing a $1 Billion ‘AI’ Research Organization | The Liberty Web –True insight into world affairs- The Online Magazine
 
In the world today, research in AI (Artificial Intelligence) has become increasingly active. Recently a new non-profit AI research organization “Open AI” was established.
The main purpose of this new organization is to prevent the monopolization and subsequent immoral use of AI by particular companies, and for people around the world to benefit from AI technology. Open AI advocates the sharing of AI program codes and research results. People who have invested in Open AI include Elon Musk (CEO of Tesla Motors) and Reid Garrett Hoffmann (co-founder of Linkedin). IT entrepreneurs and investors from Silicon Valley have invested a total of around $1 billion dollars in the research organization.
It is welcoming news that research institutes are being built to advance research in AI and to contribute to mankind.
As AI research advances, the process of work itself will change as AI replaces simple human tasks.
On the other hand, complications such as the “2045 problem” have arisen, warning of the dangers of AI and its research. The 2045 problem posits that if computer technology continues to advance at the current rate, AI will become smarter than humans by the year 2045, marking the end of the human era. That is, war between humans and AI as depicted in the “Terminator” films may become a reality. There are both expectations and fears surrounding AI research.
Elon Musk, one of the Open AI investors, says that AI will have to be debated on an international level, and warns that AI is potentially more dangerous than nuclear weapons. Similarly, Stephen Hawking says that the creation of perfect AI will mean the end of mankind.
There is much still in the dark with AI research, and the flow of mechanization and automatization cannot be avoided. As AI technology advances, however, there will arise an increasing need for all of mankind to hold values that can be shared: a base criterion of good and evil.
For instance, there is currently a conflict between Islamic and Christian values regarding the Islamic State. Massacres cannot ever be justified, but Europe and America have made Asia and Africa suffer throughout history with racial discrimination and colonizations. The Euro-American ‘Justice’ of labelling the Islamic State as the devil, and wanting to obliterate it is actually biased.
In the future, there might come a time when technology advances so much so that AI will begin to question, “What is good and what is evil?” If so, it will be imperative for the humans that create AI to know exactly what is good and what is evil.
Additionally that decision between good and evil must be one that brings happiness to many people, not one that seeks to obliterate particular groups of people or organizations. If we were to imagine what would happen if the current Communist Party of China started developing AI, it would become clear. China has assessed that countries such as Tibet and Uighur that speak against China, are ‘evil’, but this is wrong.
In other words, the precondition for accelerating AI development is that humans consider and question, “What is universal justice?” and “What is the concept of justice that goes beyond a particular area, people, or era?”